{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8152749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa5f05",
   "metadata": {},
   "source": [
    "### Reward model 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f64be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2745c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e1689272854bd88c5243ec0cc3d3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2330ee137ea440485fffd9700c702bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07f48bd415147939a5a85244b2363e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c93cb",
   "metadata": {},
   "source": [
    "### RM을 훈련시킬 때 사용할 ranking dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf42ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3b7420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce0cbc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1347.10it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 1289.53it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921cf894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52c0f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbeb0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<06:41,  1.61s/it]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:01<06:41,  1.61s/it, loss=0.7]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:49,  1.17s/it, loss=0.7]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:02<04:49,  1.17s/it, loss=1.08]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:13,  1.02s/it, loss=1.08]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:03<04:13,  1.02s/it, loss=0.425]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<03:55,  1.05it/s, loss=0.425]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:04<03:55,  1.05it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:05<03:45,  1.09it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:05<03:45,  1.09it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:39,  1.11it/s, loss=0.228]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:39,  1.11it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:35,  1.13it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:35,  1.13it/s, loss=0.38] \u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:32,  1.14it/s, loss=0.38]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:07<03:32,  1.14it/s, loss=2.74]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:30,  1.14it/s, loss=2.74]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:08<03:30,  1.14it/s, loss=0.274]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:29,  1.15it/s, loss=0.274]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:09<03:29,  1.15it/s, loss=0.53] \u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:27,  1.15it/s, loss=0.53]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:10<03:27,  1.15it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:26,  1.15it/s, loss=0.416]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:11<03:26,  1.15it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:25,  1.15it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:25,  1.15it/s, loss=0.0461]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:24,  1.15it/s, loss=0.0461]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:24,  1.15it/s, loss=1.95]  \u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:23,  1.15it/s, loss=1.95]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:23,  1.15it/s, loss=0.509]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:23,  1.15it/s, loss=0.509]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:14<03:23,  1.15it/s, loss=1.66] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:22,  1.15it/s, loss=1.66]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:15<03:22,  1.15it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:22,  1.15it/s, loss=0.774]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:16<03:22,  1.15it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:21,  1.15it/s, loss=0.468]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:17<03:21,  1.15it/s, loss=0.796]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:18<03:21,  1.14it/s, loss=0.796]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:18<03:21,  1.14it/s, loss=0.51] \u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:20,  1.14it/s, loss=0.51]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:20,  1.14it/s, loss=0.687]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:19,  1.14it/s, loss=0.687]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:19,  1.14it/s, loss=0.706]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:18,  1.14it/s, loss=0.706]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:20<03:18,  1.14it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:18,  1.14it/s, loss=0.808]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:21<03:18,  1.14it/s, loss=0.651]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:17,  1.14it/s, loss=0.651]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:22<03:17,  1.14it/s, loss=0.554]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:23<03:17,  1.14it/s, loss=0.554]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:23<03:17,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:16,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:24<03:16,  1.14it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:15,  1.13it/s, loss=0.644]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:25<03:15,  1.13it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:15,  1.13it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:15,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:14,  1.13it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:14,  1.13it/s, loss=0.496]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:13,  1.13it/s, loss=0.496]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:13,  1.13it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:28<03:13,  1.13it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:28<03:13,  1.13it/s, loss=0.864]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:29<03:12,  1.13it/s, loss=0.864]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:29<03:12,  1.13it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:11,  1.13it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:30<03:11,  1.13it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:31<03:11,  1.12it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:31<03:11,  1.12it/s, loss=0.81] \u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:32<03:10,  1.12it/s, loss=0.81]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:32<03:10,  1.12it/s, loss=0.915]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:33<03:10,  1.12it/s, loss=0.915]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:33<03:10,  1.12it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:09,  1.12it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:34<03:09,  1.12it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:08,  1.12it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:08,  1.12it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:35<03:08,  1.12it/s, loss=0.837]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:35<03:08,  1.12it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:36<03:07,  1.12it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:36<03:07,  1.12it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:37<03:06,  1.12it/s, loss=0.455]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:37<03:06,  1.12it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:38<03:05,  1.11it/s, loss=0.587]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:38<03:05,  1.11it/s, loss=0.65] \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:39<03:05,  1.11it/s, loss=0.65]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:39<03:05,  1.11it/s, loss=0.793]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:40<03:04,  1.11it/s, loss=0.793]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:40<03:04,  1.11it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:41<03:03,  1.11it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:41<03:03,  1.11it/s, loss=0.439]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:42<03:03,  1.11it/s, loss=0.439]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:42<03:03,  1.11it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:43<03:02,  1.11it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:43<03:02,  1.11it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:43<03:01,  1.11it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:43<03:01,  1.11it/s, loss=0.499]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:44<03:01,  1.10it/s, loss=0.499]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:44<03:01,  1.10it/s, loss=1.09] \u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:45<03:00,  1.10it/s, loss=1.09]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:45<03:00,  1.10it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:46<02:59,  1.10it/s, loss=0.442]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:46<02:59,  1.10it/s, loss=0.782]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:47<02:59,  1.10it/s, loss=0.782]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:47<02:59,  1.10it/s, loss=0.49] \u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:48<02:58,  1.10it/s, loss=0.49]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:48<02:58,  1.10it/s, loss=0.28]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:49<02:57,  1.10it/s, loss=0.28]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:49<02:57,  1.10it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:50<02:56,  1.10it/s, loss=0.541]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:50<02:56,  1.10it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:51<02:56,  1.09it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:51<02:56,  1.09it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:55,  1.09it/s, loss=0.582]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:52<02:55,  1.09it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:54,  1.09it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:53<02:54,  1.09it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:53<02:54,  1.09it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:53<02:54,  1.09it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:54<02:53,  1.09it/s, loss=0.481]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:54<02:53,  1.09it/s, loss=1.03] \u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:55<02:52,  1.09it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:55<02:52,  1.09it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:56<02:51,  1.09it/s, loss=0.339]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:56<02:51,  1.09it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:57<02:51,  1.09it/s, loss=0.577]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:57<02:51,  1.09it/s, loss=0.418]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:58<02:50,  1.09it/s, loss=0.418]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:58<02:50,  1.09it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:50,  1.08it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:59<02:50,  1.08it/s, loss=0.182]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:49,  1.08it/s, loss=0.182]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [01:00<02:49,  1.08it/s, loss=0.892]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:48,  1.08it/s, loss=0.892]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [01:01<02:48,  1.08it/s, loss=0.251]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:02<02:48,  1.07it/s, loss=0.251]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:02<02:48,  1.07it/s, loss=1.18] \u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:03<02:47,  1.07it/s, loss=1.18]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:03<02:47,  1.07it/s, loss=0.76]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:04<02:46,  1.07it/s, loss=0.76]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:04<02:46,  1.07it/s, loss=0.369]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:05<02:46,  1.07it/s, loss=0.369]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:05<02:46,  1.07it/s, loss=1.29] \u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:06<02:45,  1.07it/s, loss=1.29]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:06<02:45,  1.07it/s, loss=0.948]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:06<02:45,  1.07it/s, loss=0.948]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:07<02:45,  1.07it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:44,  1.06it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:07<02:44,  1.06it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:43,  1.06it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:08<02:43,  1.06it/s, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:09<02:42,  1.06it/s, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:09<02:42,  1.06it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:10<02:42,  1.06it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:10<02:42,  1.06it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:11<02:41,  1.06it/s, loss=0.507]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:11<02:41,  1.06it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:12<02:40,  1.06it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:12<02:40,  1.06it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:13<02:40,  1.06it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:13<02:40,  1.06it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:14<02:39,  1.06it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:14<02:39,  1.06it/s, loss=0.86] \u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:15<02:38,  1.05it/s, loss=0.86]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:15<02:38,  1.05it/s, loss=0.575]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:16<02:37,  1.05it/s, loss=0.575]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:16<02:37,  1.05it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:17<02:36,  1.05it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:17<02:36,  1.05it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:18<02:35,  1.05it/s, loss=0.758]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:18<02:35,  1.05it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:19<02:34,  1.05it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:19<02:34,  1.05it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:20<02:33,  1.06it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:20<02:33,  1.06it/s, loss=0.85] \u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:21<02:32,  1.06it/s, loss=0.85]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:21<02:32,  1.06it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:22<02:31,  1.06it/s, loss=0.773]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:22<02:31,  1.06it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:23<02:29,  1.06it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:23<02:29,  1.06it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:24<02:28,  1.06it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:24<02:28,  1.06it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:24<02:27,  1.06it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:24<02:27,  1.06it/s, loss=0.85] \u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:25<02:26,  1.07it/s, loss=0.85]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:25<02:26,  1.07it/s, loss=0.69]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:26<02:24,  1.07it/s, loss=0.69]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:26<02:24,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:27<02:23,  1.07it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:27<02:23,  1.07it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:28<02:22,  1.07it/s, loss=0.702]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:28<02:22,  1.07it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:29<02:21,  1.07it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:29<02:21,  1.07it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:30<02:20,  1.07it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:30<02:20,  1.07it/s, loss=0.62] \u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:31<02:19,  1.08it/s, loss=0.62]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:31<02:19,  1.08it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:32<02:18,  1.08it/s, loss=0.629]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:32<02:18,  1.08it/s, loss=0.735]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:33<02:17,  1.08it/s, loss=0.735]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:33<02:17,  1.08it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:34<02:16,  1.08it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:34<02:16,  1.08it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:35<02:15,  1.08it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:35<02:15,  1.08it/s, loss=0.827]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:36<02:13,  1.08it/s, loss=0.827]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:36<02:13,  1.08it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:37<02:13,  1.08it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:37<02:13,  1.08it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:37<02:12,  1.08it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:37<02:12,  1.08it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:38<02:10,  1.08it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:38<02:10,  1.08it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:39<02:09,  1.09it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:39<02:09,  1.09it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:40<02:08,  1.09it/s, loss=0.711]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:40<02:08,  1.09it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:41<02:07,  1.09it/s, loss=0.718]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:41<02:07,  1.09it/s, loss=0.569]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:42<02:06,  1.09it/s, loss=0.569]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:42<02:06,  1.09it/s, loss=0.66] \u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:43<02:05,  1.09it/s, loss=0.66]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:43<02:05,  1.09it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:44<02:04,  1.09it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:44<02:04,  1.09it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:45<02:03,  1.09it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:45<02:03,  1.09it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:46<02:02,  1.09it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:46<02:02,  1.09it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:47<02:01,  1.09it/s, loss=0.598]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:47<02:01,  1.09it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:48<02:01,  1.09it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:48<02:01,  1.09it/s, loss=0.542]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:48<02:00,  1.09it/s, loss=0.542]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:48<02:00,  1.09it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:49<01:58,  1.09it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:49<01:58,  1.09it/s, loss=1.08] \u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:50<01:57,  1.09it/s, loss=1.08]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:50<01:57,  1.09it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:51<01:57,  1.09it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:51<01:57,  1.09it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:52<01:56,  1.09it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:52<01:56,  1.09it/s, loss=0.524]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:53<01:55,  1.09it/s, loss=0.524]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:53<01:55,  1.09it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:54<01:54,  1.09it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:54<01:54,  1.09it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:55<01:53,  1.09it/s, loss=0.613]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:55<01:53,  1.09it/s, loss=0.766]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:56<01:52,  1.10it/s, loss=0.766]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:56<01:52,  1.10it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:57<01:51,  1.10it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:57<01:51,  1.10it/s, loss=0.632]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:58<01:50,  1.10it/s, loss=0.632]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:58<01:50,  1.10it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:58<01:49,  1.10it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:58<01:49,  1.10it/s, loss=0.602]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:59<01:48,  1.10it/s, loss=0.602]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:59<01:48,  1.10it/s, loss=0.933]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [02:00<01:47,  1.10it/s, loss=0.933]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [02:00<01:47,  1.10it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [02:01<01:46,  1.09it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [02:01<01:46,  1.09it/s, loss=0.76] \u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:02<01:46,  1.09it/s, loss=0.76]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [02:02<01:46,  1.09it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:03<01:45,  1.09it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [02:03<01:45,  1.09it/s, loss=0.706]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:04<01:44,  1.09it/s, loss=0.706]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [02:04<01:44,  1.09it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:05<01:43,  1.09it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:05<01:43,  1.09it/s, loss=0.533]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:06<01:42,  1.09it/s, loss=0.533]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:06<01:42,  1.09it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:07<01:41,  1.09it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:07<01:41,  1.09it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:08<01:40,  1.09it/s, loss=0.511]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:08<01:40,  1.09it/s, loss=0.52] \u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:09<01:39,  1.09it/s, loss=0.52]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:09<01:39,  1.09it/s, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:09<01:38,  1.09it/s, loss=0.673]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:09<01:38,  1.09it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:10<01:38,  1.09it/s, loss=0.794]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:10<01:38,  1.09it/s, loss=0.58] \u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:11<01:37,  1.09it/s, loss=0.58]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:11<01:37,  1.09it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:12<01:36,  1.09it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:12<01:36,  1.09it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:13<01:35,  1.09it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:13<01:35,  1.09it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:14<01:34,  1.09it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:14<01:34,  1.09it/s, loss=0.37] \u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:15<01:33,  1.09it/s, loss=0.37]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:15<01:33,  1.09it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:16<01:32,  1.09it/s, loss=0.664]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:16<01:32,  1.09it/s, loss=0.716]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:17<01:31,  1.09it/s, loss=0.716]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:17<01:31,  1.09it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:18<01:30,  1.09it/s, loss=0.581]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:18<01:30,  1.09it/s, loss=0.35] \u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:19<01:30,  1.09it/s, loss=0.35]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:19<01:30,  1.09it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:20<01:29,  1.09it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:20<01:29,  1.09it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:20<01:28,  1.09it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:21<01:28,  1.09it/s, loss=0.95] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:21<01:27,  1.09it/s, loss=0.95]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:21<01:27,  1.09it/s, loss=0.927]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:22<01:26,  1.09it/s, loss=0.927]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:22<01:26,  1.09it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:23<01:25,  1.09it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:23<01:25,  1.09it/s, loss=0.58]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:24<01:24,  1.09it/s, loss=0.58]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:24<01:24,  1.09it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:25<01:23,  1.09it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:25<01:23,  1.09it/s, loss=0.761]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:26<01:22,  1.09it/s, loss=0.761]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:26<01:22,  1.09it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:27<01:22,  1.08it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:27<01:22,  1.08it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:28<01:21,  1.08it/s, loss=0.693]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:28<01:21,  1.08it/s, loss=0.459]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:29<01:20,  1.08it/s, loss=0.459]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:29<01:20,  1.08it/s, loss=0.393]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:30<01:19,  1.08it/s, loss=0.393]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:30<01:19,  1.08it/s, loss=0.59] \u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:31<01:18,  1.08it/s, loss=0.59]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:31<01:18,  1.08it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:32<01:17,  1.08it/s, loss=1.03]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:32<01:17,  1.08it/s, loss=0.301]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:32<01:16,  1.08it/s, loss=0.301]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:33<01:16,  1.08it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:33<01:15,  1.08it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:33<01:15,  1.08it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:34<01:14,  1.08it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:34<01:14,  1.08it/s, loss=0.4]  \u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:35<01:14,  1.08it/s, loss=0.4]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:35<01:14,  1.08it/s, loss=0.979]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:36<01:13,  1.08it/s, loss=0.979]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:36<01:13,  1.08it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:37<01:12,  1.08it/s, loss=0.685]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:37<01:12,  1.08it/s, loss=0.871]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:38<01:11,  1.08it/s, loss=0.871]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:38<01:11,  1.08it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:39<01:10,  1.08it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:39<01:10,  1.08it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:40<01:09,  1.08it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:40<01:09,  1.08it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:41<01:08,  1.08it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:41<01:08,  1.08it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:42<01:07,  1.08it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:42<01:07,  1.08it/s, loss=0.396]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:43<01:06,  1.08it/s, loss=0.396]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:43<01:06,  1.08it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:44<01:05,  1.08it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:44<01:05,  1.08it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:45<01:04,  1.08it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:45<01:04,  1.08it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:45<01:03,  1.08it/s, loss=0.737]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:45<01:03,  1.08it/s, loss=0.351]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:46<01:02,  1.08it/s, loss=0.351]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:46<01:02,  1.08it/s, loss=1.04] \u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:47<01:01,  1.08it/s, loss=1.04]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:47<01:01,  1.08it/s, loss=0.939]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:48<01:00,  1.08it/s, loss=0.939]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:48<01:00,  1.08it/s, loss=0.857]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:49<01:00,  1.08it/s, loss=0.857]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:49<01:00,  1.08it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:50<00:59,  1.08it/s, loss=0.579]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:50<00:59,  1.08it/s, loss=0.43] \u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:51<00:58,  1.08it/s, loss=0.43]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:51<00:58,  1.08it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:52<00:57,  1.08it/s, loss=0.367]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:52<00:57,  1.08it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:53<00:56,  1.08it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:53<00:56,  1.08it/s, loss=0.778]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:54<00:55,  1.08it/s, loss=0.778]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:54<00:55,  1.08it/s, loss=0.38] \u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:55<00:54,  1.08it/s, loss=0.38]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:55<00:54,  1.08it/s, loss=0.313]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:56<00:53,  1.08it/s, loss=0.313]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:56<00:53,  1.08it/s, loss=0.45] \u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:57<00:52,  1.08it/s, loss=0.45]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:57<00:52,  1.08it/s, loss=0.844]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:57<00:51,  1.08it/s, loss=0.844]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:57<00:51,  1.08it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:58<00:50,  1.08it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:58<00:50,  1.08it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:59<00:49,  1.08it/s, loss=0.366]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:59<00:49,  1.08it/s, loss=0.956]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [03:00<00:48,  1.08it/s, loss=0.956]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [03:00<00:48,  1.08it/s, loss=0.57] \u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [03:01<00:47,  1.09it/s, loss=0.57]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [03:01<00:47,  1.09it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [03:02<00:47,  1.08it/s, loss=0.543]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [03:02<00:47,  1.08it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [03:03<00:46,  1.09it/s, loss=0.382]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [03:03<00:46,  1.09it/s, loss=0.414]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:04<00:45,  1.08it/s, loss=0.414]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [03:04<00:45,  1.08it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:05<00:44,  1.09it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [03:05<00:44,  1.09it/s, loss=0.917]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:06<00:43,  1.09it/s, loss=0.917]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [03:06<00:43,  1.09it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:07<00:42,  1.09it/s, loss=0.661]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [03:07<00:42,  1.09it/s, loss=0.515]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:08<00:41,  1.09it/s, loss=0.515]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [03:08<00:41,  1.09it/s, loss=0.544]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:08<00:40,  1.09it/s, loss=0.544]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:09<00:40,  1.09it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:09<00:39,  1.09it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:09<00:39,  1.09it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:10<00:38,  1.09it/s, loss=0.532]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:10<00:38,  1.09it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:11<00:37,  1.09it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:11<00:37,  1.09it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:12<00:36,  1.09it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:12<00:36,  1.09it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:13<00:35,  1.09it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:13<00:35,  1.09it/s, loss=0.439]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:14<00:34,  1.09it/s, loss=0.439]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:14<00:34,  1.09it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:15<00:34,  1.09it/s, loss=0.536]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:15<00:34,  1.09it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:16<00:33,  1.09it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:16<00:33,  1.09it/s, loss=1.12] \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:17<00:32,  1.09it/s, loss=1.12]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:17<00:32,  1.09it/s, loss=0.544]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:18<00:31,  1.09it/s, loss=0.544]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:18<00:31,  1.09it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:19<00:30,  1.09it/s, loss=0.802]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:19<00:30,  1.09it/s, loss=0.883]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:20<00:29,  1.09it/s, loss=0.883]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:20<00:29,  1.09it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:20<00:28,  1.09it/s, loss=0.547]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:20<00:28,  1.09it/s, loss=0.405]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:21<00:27,  1.09it/s, loss=0.405]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:21<00:27,  1.09it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:22<00:26,  1.09it/s, loss=0.676]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:22<00:26,  1.09it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:23<00:25,  1.09it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:23<00:25,  1.09it/s, loss=0.361]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:24<00:24,  1.09it/s, loss=0.361]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:24<00:24,  1.09it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:25<00:23,  1.09it/s, loss=0.683]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:25<00:23,  1.09it/s, loss=0.704]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:26<00:22,  1.09it/s, loss=0.704]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:26<00:22,  1.09it/s, loss=0.639]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:27<00:22,  1.09it/s, loss=0.639]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:27<00:22,  1.09it/s, loss=0.633]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:28<00:21,  1.09it/s, loss=0.633]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:28<00:21,  1.09it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:29<00:20,  1.09it/s, loss=0.745]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:29<00:20,  1.09it/s, loss=0.55] \u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:30<00:19,  1.09it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:30<00:19,  1.09it/s, loss=0.715]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:31<00:18,  1.09it/s, loss=0.715]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:31<00:18,  1.09it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:31<00:17,  1.09it/s, loss=0.705]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:32<00:17,  1.09it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:32<00:16,  1.09it/s, loss=0.447]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:32<00:16,  1.09it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:33<00:15,  1.09it/s, loss=0.792]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:33<00:15,  1.09it/s, loss=0.479]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:34<00:14,  1.09it/s, loss=0.479]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:34<00:14,  1.09it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:35<00:13,  1.09it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:35<00:13,  1.09it/s, loss=0.854]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:36<00:12,  1.09it/s, loss=0.854]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:36<00:12,  1.09it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:37<00:11,  1.09it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:37<00:11,  1.09it/s, loss=0.524]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:38<00:11,  1.09it/s, loss=0.524]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:38<00:11,  1.09it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:39<00:10,  1.09it/s, loss=0.732]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:39<00:10,  1.09it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:40<00:09,  1.09it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:40<00:09,  1.09it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:41<00:08,  1.09it/s, loss=0.583]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:41<00:08,  1.09it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:42<00:07,  1.09it/s, loss=0.552]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:42<00:07,  1.09it/s, loss=0.812]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:43<00:06,  1.09it/s, loss=0.812]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:43<00:06,  1.09it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:43<00:05,  1.09it/s, loss=0.503]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:43<00:05,  1.09it/s, loss=0.6]  \u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:44<00:04,  1.09it/s, loss=0.6]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:44<00:04,  1.09it/s, loss=0.828]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:45<00:03,  1.09it/s, loss=0.828]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:45<00:03,  1.09it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:46<00:02,  1.09it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:46<00:02,  1.09it/s, loss=0.343]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:47<00:01,  1.09it/s, loss=0.343]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:47<00:01,  1.09it/s, loss=1.21] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:48<00:00,  1.09it/s, loss=1.21]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:48<00:00,  1.09it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:49<00:00,  1.09it/s, loss=0.614]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [04:04<00:00, 244.69s/it]0,  1.09it/s, loss=0.477]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [04:04<00:00,  1.02it/s, loss=0.626, dist_mean=0.294]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [04:04<00:00, 244.69s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c76510a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: -0.3\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e164973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: -0.3\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539738c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: -0.1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5955b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: 0.1\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
